{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092c49c8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3330a4f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a735be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6bbeca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'App_Logger' from 'app_logger' (C:\\Users\\dell\\anaconda3\\lib\\site-packages\\app_logger\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../scripts\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfile_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileHandler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\pharmaceutical-sales-prediction\\scripts\\file_handler.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../scripts\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m App_Logger\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFileHandler\u001b[39;00m():\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# self.logger = App_Logger().get_logger(__name__)\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'App_Logger' from 'app_logger' (C:\\Users\\dell\\anaconda3\\lib\\site-packages\\app_logger\\__init__.py)"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from file_handler import FileHandler\n",
    "from eda import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea8781",
   "metadata": {},
   "source": [
    "## Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c313c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FileHandler object\n",
    "file_handler = FileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9730f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the store csv file\n",
    "store_df = file_handler.read_csv(\"../data/store.csv\")\n",
    "store_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the sales training csv file\n",
    "train_df = file_handler.read_csv(\"../data/train.csv\")\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1819f95",
   "metadata": {},
   "source": [
    "## General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(store_df, size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(store_df, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(store_df, describe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1685e99",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(train_df, size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(train_df, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(train_df, describe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89af74",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ce5e4",
   "metadata": {},
   "source": [
    "### Store dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_values(store_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356102a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = missing_values_table(store_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50527b",
   "metadata": {},
   "source": [
    " It shows that the first 3 columns and the next 2 columns have the same number of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows with missing values for the whole dataset\n",
    "count_missing_rows(store_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581322b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows with missing values for Promo2SinceWeek, Promo2SinceYear, and PromoInterval\n",
    "count_missing_rows(store_df[['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows with missing values for group 2 (CompetitionOpenSinceMonth, and CompetitionOpenSinceYear)\n",
    "count_missing_rows(store_df[['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fabb06",
   "metadata": {},
   "source": [
    "Each columuns in these groups have missing values in the same rows as their groupmates. These means the missing values in these groups appear at the same time as a cluster. Therefore, the values of the columns in each group share a common information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a631795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing the missing rows for columns in group 1\n",
    "group1_df = store_df[store_df['Promo2SinceWeek'].isna()]\n",
    "group1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202b93a",
   "metadata": {},
   "source": [
    "We can see that the Promo2 column is 0 for the first 10 rows. From intution we can infer that if there is no promotion the values for the columns in Promo2SinceWeek, Promo2SinceYear, and PromoInterval should be null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168512fc",
   "metadata": {},
   "source": [
    "Therefore, we can impute the missing values in the columns Promo2SinceWeek and Promo2SinceYear with 0 to convey the meaning of absence since year and week can't be 0. But as for PromoInterval further investigation is needed since its data type is object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the exact data type of the object\n",
    "pd.api.types.infer_dtype(store_df['PromoInterval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the unique values \n",
    "store_df['PromoInterval'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a26fe4",
   "metadata": {},
   "source": [
    "For the column PromoInterval, we will impute it with '0,0,0,0' as the other values follow list-type format containing four months. So inorder to impute these columns we should first investigate if the values we will insert exist in each column as this will oppose our intention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df[store_df['Promo2SinceWeek'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df[store_df['Promo2SinceYear'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df[store_df['PromoInterval'] == '0,0,0,0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa025355",
   "metadata": {},
   "source": [
    "Since the values don't appear in these columns, let's fill the missing values by '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_missing_value(store_df, ['Promo2SinceWeek', 'Promo2SinceYear'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659059a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_missing_value(store_df, ['PromoInterval'], '0,0,0,0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing the missing rows for columns in the second group\n",
    "group2_df = store_df[store_df['CompetitionOpenSinceMonth'].isna()]\n",
    "group2_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42856232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unique values for each column in the dataframe\n",
    "unique_values_df(group2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56202a",
   "metadata": {},
   "source": [
    "Since there is no pattern between each columns the conclusion would be that CompetitionOpenSinceMonth and CompetitionOpenSinceYear are null because there was already a competition when the store was opened. So let's create another column called CompetitionBeforeStoreOpened which holds values of 0 and 1, 0 indicating the absence of competition at the time the store was opened and 1 indicating the presence of competition at the time the store was opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deriving new column\n",
    "store_df['CompetitionBeforeStoreOpened'] = store_df['CompetitionOpenSinceYear'].apply(lambda x: 1 if np.isnan(x) else 0)\n",
    "store_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f1f8c",
   "metadata": {},
   "source": [
    "Impututing the missing values in the column CompetitionOpenSinceYear and CompetitionOpenSinceMonth with its minimun value and 1 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c295b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = store_df['CompetitionOpenSinceYear'].min()\n",
    "min_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3137ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the column CompetitionOpenSinceYear with 1900 and the column CompetitionOpenSinceMonth with 1\n",
    "fix_missing_value(store_df, ['CompetitionOpenSinceYear'], min_year)\n",
    "fix_missing_value(store_df, ['CompetitionOpenSinceMonth'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343d004",
   "metadata": {},
   "source": [
    "Handling missing values of column CompetitionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = store_df[store_df['CompetitionDistance'].isna()]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_df(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2c926",
   "metadata": {},
   "source": [
    "All rows with missing values in the column CompetitionDistance has a value of 1 in the column CompetitionBeforeStoreOpened. This is because the competitions for these stores are very far away and have almost no impact on these stores that they weren't measured when collecting the data. For this reason, I will impute thess values with the maximum competition distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = store_df['CompetitionDistance'].max()\n",
    "max_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_missing_value(store_df, ['CompetitionDistance'], max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9092467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check for missing values\n",
    "percent_missing_values(store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5973aa5",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_values(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196132d8",
   "metadata": {},
   "source": [
    "## Handling data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a854ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18219a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns with object data type\n",
    "string_columns = store_df.select_dtypes(include='object').columns.tolist()\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891acf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_string(store_df, string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the columns to int as they cannot be floats.\n",
    "convert_to_int(store_df, ['CompetitionOpenSinceMonth',  'CompetitionOpenSinceYear',\n",
    "        'Promo2SinceWeek', 'Promo2SinceYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89528b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if there is mixed data type in the train dataset.\n",
    "show_cols_mixed_dtypes(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ece23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['StateHoliday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['StateHoliday'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_string(train_df, ['StateHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81754587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_datetime(train_df, ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ffa02",
   "metadata": {},
   "source": [
    "## Handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d49174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for duplicate rows and drop them\n",
    "drop_duplicates(store_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4453cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for duplicate rows and drop them\n",
    "drop_duplicates(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9fb9f7",
   "metadata": {},
   "source": [
    "## Handling Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Year'] = train_df['Date'].apply(lambda x: x.year)\n",
    "train_df['Month'] = train_df['Date'].apply(lambda x: x.month)\n",
    "train_df['DayOfMonth'] = train_df['Date'].apply(lambda x: x.day)\n",
    "train_df['WeekOfYear'] = train_df['Date'].apply(lambda x: x.weekofyear)\n",
    "train_df['weekday'] = train_df['DayOfWeek'].apply(lambda x: 0 if (x in [6, 7]) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonth(month_list, index):\n",
    "    months = ['0', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "    month_list = month_list.split(',')\n",
    "    month = month_list[index]\n",
    "    return months.index(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9364e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the PromoInterval column into 4 columns\n",
    "store_df['PromoInterval0'] = store_df.PromoInterval.apply((lambda x: getMonth(x, 0)))\n",
    "store_df['PromoInterval1'] = store_df.PromoInterval.apply((lambda x: getMonth(x, 1)))\n",
    "store_df['PromoInterval2'] = store_df.PromoInterval.apply((lambda x: getMonth(x, 2)))\n",
    "store_df['PromoInterval3'] = store_df.PromoInterval.apply((lambda x: getMonth(x, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the clean dataframe to a csv file\n",
    "file_handler.to_csv(train_df, '../data/eda/train.csv')\n",
    "file_handler.to_csv(store_df, '../data/eda/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddd469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db9540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
